<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-1168479-8"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-1168479-8');
    </script>
    <style>
            a {
                color: #1772d0;
                text-decoration:none;
            }
            a:focus, a:hover {
                color: #f09228;
                text-decoration:none;
            }

      html { scroll-behavior: smooth; }
      body {
        font-family: Helvetica, Helvetica, sans-serif;
        <!-- background-color: #333;
        color: white-->}
      p {line-height: 26px;}
      main.container {max-width: 960px;}
      span.p-title {font-size: 16px;}
      span.p-authors {font-style: normal;font-size: 16px;}
      span.p-conference {font-style: italic;;font-size: 16px;}
      .p-bibtex {font-size: 12px; margin-bottom: 0px; max-width: 650px; text-align: left;}
      img.p-teaser {width: 200px;}
      img.profile {
        width: 160px;
        height: 160px;
        border: 1px solid #ddd;
        padding: 5px;
        box-shadow: 0 -1px 5px 1px rgba(200, 200, 200, 0.5);
      }
    </style>

    <title>Xin Yao</title>
  </head>

  <body>
    <main class="container">
      <div class="mt-5 mb-5 text-center">
          <div class="text-center text-sm-center">
            <h2>Rebar Counting based on Object Detection</h2>
        
	    <br>
          </div>
      </div>

      <h4 class="mb-3 text-center text-sm-left">Background</h4>

    <p>
      In the area of construction engineering and management, accurate rebar (reinforcing bar) detection and counting are crucial for ensuring structural integrity, compliance with design specifications, and efficient use of materials. Rebars are used extensively in concrete reinforcement, and their precise placement and quantity are vital for the strength and durability of concrete structures.
    </p>
    <p>The importance of rebar counting:</p>
    <p>Structural Integrity: The strength and resilience of reinforced concrete structures heavily depend on the correct placement and quantity of rebars. Inaccurate rebar installation can lead to structural weaknesses, making buildings susceptible to damage under stress.
    </p>
    <p>Cost Efficiency: Precise rebar counting helps in estimating the exact amount of material needed, avoiding wastage, and ensuring cost-effective construction practices.
    </p>
    <p>Compliance and Safety: Adhering to the architectural and engineering specifications is paramount for construction projects. Accurate rebar counting ensures compliance with these specifications, contributing to the overall safety of the construction.
    </p>

    <p>The challenges of rebar counting are:</p>
    <p>Complexity of Detection: Rebars in construction images are often closely packed, overlapped, or partially obscured, making their detection a challenging task for traditional image processing techniques.
    </p>
    <p>Variability of Conditions: The appearance of rebars can significantly vary due to lighting conditions, angles of capture, and the presence of construction materials or debris, further complicating the detection process.
    </p>
    <p>Scale and Density: Construction projects can vary greatly in scale, and the density of rebars in images can range from sparse to extremely dense clusters, requiring a robust detection system capable of handling such variability.
    </p>
    <p>Real-time Processing Needs: In many cases, there's a requirement for real-time or near-real-time processing of images to provide timely feedback to construction teams, posing additional computational challenges.</p>


    <h4 class="mb-3 text-center text-sm-left">YOLOv9</h4>
    <p>
      Existing methods overlook significant information loss during deep network operations. YOLOv9 addresses this by introducing Programmable Gradient Information (PGI) to combat data loss issues. PGI ensures comprehensive input data for target tasks, enabling reliable gradient information for weight updates. Additionally, YOLOv9 presents a Generalized Efficient Layer Aggregation Network (GELAN), outperforming state-of-the-art methods in parameter utilization, even with conventional convolution operators. PGI's versatility extends to various model sizes, offering superior performance for train-from-scratch models. Source code: https://github.com/WongKinYiu/yolov9. 
    </p>


    <h4 class="mb-3 text-center text-sm-left">Rebar dataset</h4>
    <div class="text-center">
      <img src="Rebar1.jpg" class="mr-15 p-teaser mb-sm-5" style="width: 80%;" />
    </div>
    <p>
      Dataset for IJCAI 2021 paper "Object Detection in Densely Packed Scenes via Semi-Supervised Learning with Dual Consistency" 
    </p>
    <p>RebarDSC is a new dataset of the industrial rebar collection scene. To construct this dataset:</p>
    <p>We collected 2,125 images from the top 3 rebar manufacturing companies in Asia, where the images are captured in the real production environment with various types of mobile devices, with resolution vary from 800×600 to 4600×3400;</p>
    <p>To satisfy the requirement of bundle counting, we capture all the raw images with a bundle of rebar as the image center. If two or more bundles are captured, we only considered the rebar within the bundle closing to the image center and ignored other bundles.</p>
    <p>We hired professional human workers from rebar manufacturing companies to annotate each image’s bounding box, and finally, 350,348 annotations, 164.9 annotations per image are collected.</p>


    <h4 class="mb-3 text-center text-sm-left">Examine training results</h4>
	<p>Now we can examine the training results by showing the plotted training/validation loss and metrics during training.</p>
    <div class="text-center">
      <img src="TrainingResults.jpg" class="mr-15 p-teaser mb-sm-5" style="width: 80%;" />
    </div>



    <h4 class="mb-3 text-center text-sm-left">Testing the new YOLOv9 model on the Rebar testset</h4>
    <p>
      Run let's run the new detect.py file to get all the results.
      Please remember to set the experiment ID, corresponding to the training procedure above, in --weights runs/train/<expID>/weights/best.pt.
      After running through all the 1000 test images. You should be able to get an accuracy around 98%.
    </p>
    <div class="text-center">
      <img src="TestResults.jpg" class="mr-15 p-teaser mb-sm-5" style="width: 80%;" />
    </div>
  


    </main>





    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  </body>
</html>
